{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movie_Reviews_LSTMs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArshT/Mini-Projects/blob/master/Movie_Reviews_LSTMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U82Y64ldtpPu",
        "colab_type": "code",
        "outputId": "cb3c05fa-cfd9-4e5d-9513-de33ea0e850d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "###Importing Important Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten,LSTM,Bidirectional\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTigkacxuBK0",
        "colab_type": "code",
        "outputId": "8f7463c4-3215-450d-87c8-fc6c3986c0ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "###Mounting the Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTqXTgUEuMQg",
        "colab_type": "code",
        "outputId": "6682ca8c-b28f-47aa-b869-0b8bc40ef7fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd '/content/drive/My Drive'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB8dbo9JwbtZ",
        "colab_type": "code",
        "outputId": "770d222c-7098-4e01-8e4c-300ed304c05b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "###Importing the Data\n",
        "\n",
        "movie_reviews = pd.read_csv('imdb_master.csv',encoding = \"ISO-8859-1\")\n",
        "movie_reviews.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>type</th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "      <th>file</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
              "      <td>neg</td>\n",
              "      <td>0_2.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "      <td>This is an example of why the majority of acti...</td>\n",
              "      <td>neg</td>\n",
              "      <td>10000_4.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>test</td>\n",
              "      <td>First of all I hate those moronic rappers, who...</td>\n",
              "      <td>neg</td>\n",
              "      <td>10001_1.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>test</td>\n",
              "      <td>Not even the Beatles could write songs everyon...</td>\n",
              "      <td>neg</td>\n",
              "      <td>10002_3.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>test</td>\n",
              "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
              "      <td>neg</td>\n",
              "      <td>10003_3.txt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  type  ... label         file\n",
              "0           0  test  ...   neg      0_2.txt\n",
              "1           1  test  ...   neg  10000_4.txt\n",
              "2           2  test  ...   neg  10001_1.txt\n",
              "3           3  test  ...   neg  10002_3.txt\n",
              "4           4  test  ...   neg  10003_3.txt\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_L-W_QkwgDt",
        "colab_type": "code",
        "outputId": "cbde5d0f-e9f5-4d33-9bd6-6b1a2ac7ddbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "###Checking for missing Values\n",
        "\n",
        "movie_reviews.isnull().values.any()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cfkvE3dxVSP",
        "colab_type": "code",
        "outputId": "358b5ff5-b6b8-49e2-c190-24f7283f38a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "###Checking for Shape of DataFrame\n",
        "\n",
        "movie_reviews.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h8kKP32xgAk",
        "colab_type": "code",
        "outputId": "1121e8cf-16f6-43b0-a64a-d16fde75d8c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "###Unique Values of Label\n",
        "\n",
        "movie_reviews['label'].unique()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['neg', 'pos', 'unsup'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n37krUwGx1To",
        "colab_type": "code",
        "outputId": "37e45ace-1680-45a7-c58b-5654f6349ace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "###Removing the unsup training examples\n",
        "\n",
        "train = movie_reviews[movie_reviews['label'] != 'unsup']\n",
        "train.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPuj6Mw3yTWn",
        "colab_type": "code",
        "outputId": "dd6eb95f-dcdd-4f3b-dfd0-8cb42347cfa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "###Example of a Review \n",
        "\n",
        "train['review'][5]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A funny thing happened to me while watching \"Mosquito\": on the one hand, the hero is a deaf-mute and the director is totally unable to make us understand why he does what he does (mutilating mannequins...er, excuse me, corpses) through his images. On the other hand, the English version at least is very badly dubbed. So I found myself wishing there had been both more AND less dialogue at the same time! This film is stupid (funny how this guy has access to every graveyard and mortuary in his town) and lurid (where would we be in a 70s exploitationer without our gratuitous lesbian scene?). Not to mention the \"romantic\" aspect (oh, how sweet!)...Miss it. (*)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg8DJ3G8vkN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Pre-Processing the reviews\n",
        "\n",
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_tags(text):\n",
        "    return TAG_RE.sub('', text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDlv4Ml4yc_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Function for Pre-Processing of the Reviews\n",
        "\n",
        "def preprocess_text(sen):\n",
        "\n",
        "  #Removing the HTML Tags\n",
        "  sentence = remove_tags(sen)\n",
        "\n",
        "  #Removing Single Characters\n",
        "  sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "  #Removing multiple spaces\n",
        "  sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "  return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AISsoPDtzowc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Creating the Dataset after Pre-Processing\n",
        "\n",
        "##X\n",
        "X = []\n",
        "sentences = list(train['review'])\n",
        "for sen in sentences:\n",
        "  X.append(preprocess_text(sen))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiRelkq70Im-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Y\n",
        "\n",
        "Y = train['label']\n",
        "Y = np.array(list(map(lambda x: 1 if x==\"pos\" else 0, Y)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFDlncGX0iny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Splitting the Dataset for Training and Testing\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whQ4VOJn0zGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Making a Vocabulary by Tokenizing, then the list of sentences will be converted to Indices.  \n",
        "\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXbGG-8X2OxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Declaring the Vocabulary Size and also restricting the reviews to a max length\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "maxlen = 100\n",
        "\n",
        "\n",
        "##Padding to make the Length Uniform\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOz5MPo-30Ou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "###Creating the Embedding matrix using GloVe\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in glove_file:\n",
        "  records = line.split()\n",
        "  word = records[0]\n",
        "  vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
        "  embeddings_dictionary [word] = vector_dimensions\n",
        "glove_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0EhSORP5T0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-mH5hFa5ont",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Model\n",
        "\n",
        "model = Sequential()\n",
        "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "model.add(embedding_layer)\n",
        "model.add(Bidirectional(LSTM(128,return_sequences=True)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvgRjjHJ-vUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Compiling the Model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG-KKIMiHp4-",
        "colab_type": "code",
        "outputId": "623a17d1-8d42-4534-d29e-7388acff131f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "###Training the Model\n",
        "\n",
        "history = model.fit(X_train, Y_train, batch_size=256, epochs=10, verbose=1, validation_split=0.2)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 32000 samples, validate on 8000 samples\n",
            "Epoch 1/10\n",
            "32000/32000 [==============================] - 56s 2ms/step - loss: 0.5605 - acc: 0.7226 - val_loss: 0.4898 - val_acc: 0.7699\n",
            "Epoch 2/10\n",
            "32000/32000 [==============================] - 56s 2ms/step - loss: 0.4708 - acc: 0.7819 - val_loss: 0.4519 - val_acc: 0.7817\n",
            "Epoch 3/10\n",
            "32000/32000 [==============================] - 55s 2ms/step - loss: 0.4321 - acc: 0.8016 - val_loss: 0.4123 - val_acc: 0.8096\n",
            "Epoch 4/10\n",
            "32000/32000 [==============================] - 56s 2ms/step - loss: 0.3944 - acc: 0.8242 - val_loss: 0.4220 - val_acc: 0.8067\n",
            "Epoch 5/10\n",
            "32000/32000 [==============================] - 55s 2ms/step - loss: 0.3692 - acc: 0.8357 - val_loss: 0.3658 - val_acc: 0.8334\n",
            "Epoch 6/10\n",
            "32000/32000 [==============================] - 55s 2ms/step - loss: 0.3398 - acc: 0.8506 - val_loss: 0.3500 - val_acc: 0.8488\n",
            "Epoch 7/10\n",
            "32000/32000 [==============================] - 56s 2ms/step - loss: 0.3174 - acc: 0.8619 - val_loss: 0.3531 - val_acc: 0.8430\n",
            "Epoch 8/10\n",
            "32000/32000 [==============================] - 55s 2ms/step - loss: 0.3036 - acc: 0.8683 - val_loss: 0.3595 - val_acc: 0.8530\n",
            "Epoch 9/10\n",
            "32000/32000 [==============================] - 55s 2ms/step - loss: 0.2902 - acc: 0.8757 - val_loss: 0.3323 - val_acc: 0.8575\n",
            "Epoch 10/10\n",
            "32000/32000 [==============================] - 55s 2ms/step - loss: 0.2741 - acc: 0.8860 - val_loss: 0.3259 - val_acc: 0.8590\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT5fhoooIPw7",
        "colab_type": "code",
        "outputId": "d478363a-ed32-4cc5-8201-c0a9f96c33f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "###Testing the Model\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=1)\n",
        "score"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 49s 5ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3158712195396423, 0.8631]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}