{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"###Importing Important Libraries\n\nimport numpy as np\nimport pandas as pd\nimport keras\nimport matplotlib.pyplot as plt\nimport os\nimport random\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential,Model\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"###Unzipping the Data\nimport zipfile\n\n##Train\nlocal_zip_train = '/kaggle/input/aerial-cactus-identification/train.zip'\nzip_ref = zipfile.ZipFile(local_zip_train, 'r')\nzip_ref.extractall('/kaggle/working')\nzip_ref.close()\n\n##Test\nlocal_zip_test = '/kaggle/input/aerial-cactus-identification/test.zip'\nzip_ref = zipfile.ZipFile(local_zip_test, 'r')\nzip_ref.extractall('/kaggle/working')\nzip_ref.close()","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Image Hyperparameters\n\nIMAGE_SIZE = 150\nIMAGE_WIDTH, IMAGE_HEIGHT = IMAGE_SIZE,IMAGE_SIZE\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS=3","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd '/kaggle/input/aerial-cactus-identification'","execution_count":4,"outputs":[{"output_type":"stream","text":"/kaggle/input/aerial-cactus-identification\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('train.csv')\ndf.head()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"                                     id  has_cactus\n0  0004be2cfeaba1c0361d39e2b000257b.jpg           1\n1  000c8a36845c0208e833c79c1bffedd1.jpg           1\n2  000d1e9a533f62e55c289303b072733d.jpg           1\n3  0011485b40695e9138e92d0b3fb55128.jpg           1\n4  0014d7a11e90b62848904c1418fc8cf2.jpg           1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>has_cactus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0004be2cfeaba1c0361d39e2b000257b.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000c8a36845c0208e833c79c1bffedd1.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000d1e9a533f62e55c289303b072733d.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0011485b40695e9138e92d0b3fb55128.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0014d7a11e90b62848904c1418fc8cf2.jpg</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"has_cactus\"] = df[\"has_cactus\"].replace({0: 'No', 1: 'Yes'}) ","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"                                     id has_cactus\n0  0004be2cfeaba1c0361d39e2b000257b.jpg        Yes\n1  000c8a36845c0208e833c79c1bffedd1.jpg        Yes\n2  000d1e9a533f62e55c289303b072733d.jpg        Yes\n3  0011485b40695e9138e92d0b3fb55128.jpg        Yes\n4  0014d7a11e90b62848904c1418fc8cf2.jpg        Yes","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>has_cactus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0004be2cfeaba1c0361d39e2b000257b.jpg</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000c8a36845c0208e833c79c1bffedd1.jpg</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000d1e9a533f62e55c289303b072733d.jpg</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0011485b40695e9138e92d0b3fb55128.jpg</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0014d7a11e90b62848904c1418fc8cf2.jpg</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Making the Model\nfrom keras.applications import VGG16\n\ninput_shape = (IMAGE_HEIGHT,IMAGE_WIDTH,IMAGE_CHANNELS)\n\nmodel = Sequential\n\npre_trained_model = VGG16(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n\nfor layer in pre_trained_model.layers[:15]:\n    layer.trainable = False\nfor layer in pre_trained_model.layers[15:]:\n    layer.trainable = True\n\nlast_layer = pre_trained_model.get_layer('block5_pool')\nlast_output = last_layer.output\n\n# Flatten the output layer to 1 dimension\nx = Flatten()(last_output)\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = Dense(512, activation='relu')(x)\n# Add a dropout rate of 0.5\nx = Dropout(0.5)(x)\n# Add a final sigmoid layer for classification\nx = Dense(1, activation='sigmoid')(x)\n\nmodel = Model(pre_trained_model.input, x)","execution_count":8,"outputs":[{"output_type":"stream","text":"Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58892288/58889256 [==============================] - 2s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Compiling the Model\n\nmodel.compile(optimizer = 'adam',loss='binary_crossentropy',metrics=['accuracy'])","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Model Summary\n\nmodel.summary()","execution_count":10,"outputs":[{"output_type":"stream","text":"Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 150, 150, 3)       0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 8192)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               4194816   \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 513       \n=================================================================\nTotal params: 18,910,017\nTrainable params: 11,274,753\nNon-trainable params: 7,635,264\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Callbacks\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\nearlystop = EarlyStopping(patience=10)\n\ncallbacks = [earlystop, learning_rate_reduction]","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Preparing the Data\n\ntrain_df, validate_df = train_test_split(df, test_size=0.10, random_state=42)\ntrain_df = train_df.reset_index(drop=True)\nvalidate_df = validate_df.reset_index(drop=True)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Hyperparameters\n\n\ntotal_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]\nbatch_size=64\nepochs = 15","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Generator\n\n##Train\ntrain_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1./255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    \"/kaggle/working/train\", \n    x_col='id',\n    y_col='has_cactus',\n    target_size=IMAGE_SIZE,\n    class_mode='binary',\n    batch_size=batch_size\n)","execution_count":20,"outputs":[{"output_type":"stream","text":"Found 15750 validated image filenames belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n##Val \nvalidation_datagen = ImageDataGenerator(rescale=1./255)\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    \"/kaggle/working/train\", \n    x_col='id',\n    y_col='has_cactus',\n    target_size=IMAGE_SIZE,\n    class_mode='binary',\n    batch_size=batch_size\n)","execution_count":21,"outputs":[{"output_type":"stream","text":"Found 1750 validated image filenames belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Training the Model\n\nhistory = model.fit_generator(\n    train_generator, \n    epochs=5,\n    validation_data=validation_generator,\n    validation_steps=total_validate//batch_size,\n    steps_per_epoch=total_train//batch_size,\n    callbacks=callbacks\n)","execution_count":16,"outputs":[{"output_type":"stream","text":"Epoch 1/5\n246/246 [==============================] - 87s 354ms/step - loss: 0.1808 - accuracy: 0.9269 - val_loss: 0.0917 - val_accuracy: 0.9705\nEpoch 2/5\n  1/246 [..............................] - ETA: 22s - loss: 0.0389 - accuracy: 0.9688","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy,lr\n  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n","name":"stderr"},{"output_type":"stream","text":"246/246 [==============================] - 85s 345ms/step - loss: 0.0673 - accuracy: 0.9783 - val_loss: 0.0258 - val_accuracy: 0.9846\nEpoch 3/5\n246/246 [==============================] - 84s 343ms/step - loss: 0.0451 - accuracy: 0.9836 - val_loss: 0.0437 - val_accuracy: 0.9858\nEpoch 4/5\n246/246 [==============================] - 85s 345ms/step - loss: 0.0477 - accuracy: 0.9836 - val_loss: 0.0552 - val_accuracy: 0.9887\nEpoch 5/5\n246/246 [==============================] - 86s 349ms/step - loss: 0.0553 - accuracy: 0.9840 - val_loss: 0.0178 - val_accuracy: 0.9911\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Testing\n\n##Creating a test DataFrame\nfilenames_test = os.listdir(\"/kaggle/working/test\")\nprint(len(filenames_test))\n\ndf_test = pd.DataFrame({\n    'id': filenames_test,\n})","execution_count":22,"outputs":[{"output_type":"stream","text":"4000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Creating the Test Image Generator\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntest_generator=test_datagen.flow_from_dataframe(\ndataframe=df_test,\ndirectory=\"/kaggle/working/test\",\nx_col=\"id\",\ny_col=None,\nbatch_size=32,\nshuffle=False,\nclass_mode=None,\ntarget_size=(IMAGE_HEIGHT,IMAGE_WIDTH))","execution_count":23,"outputs":[{"output_type":"stream","text":"Found 4000 validated image filenames.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Predicting\nSTEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n\npred=model.predict_generator(test_generator,\nsteps=STEP_SIZE_TEST,\nverbose=1)","execution_count":24,"outputs":[{"output_type":"stream","text":"125/125 [==============================] - 6s 46ms/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = np.where(pred > 0.5, 1, 0)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd '/kaggle/working'","execution_count":34,"outputs":[{"output_type":"stream","text":"/kaggle/working\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = df_test\nprediction['label'] = pred\nprediction.to_csv('Prediction.csv') ","execution_count":35,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}