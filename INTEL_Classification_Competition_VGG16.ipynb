{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"###Importing the Important Libraries\n\nimport numpy as np\nimport pandas as pd\nimport keras\nimport matplotlib.pyplot as plt\nimport keras\nimport os\nimport random\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential,Model\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"cd '/kaggle/working'","execution_count":2,"outputs":[{"output_type":"stream","text":"/kaggle/working\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"mkdir train","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mkdir test","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cp -a /kaggle/input/intel-image-classification/seg_train/seg_train/forest/. /kaggle/working/train","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cp -a /kaggle/input/intel-image-classification/seg_train/seg_train/glacier/. /kaggle/working/train","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cp -a /kaggle/input/intel-image-classification/seg_train/seg_train/buildings/. /kaggle/working/train","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cp -a /kaggle/input/intel-image-classification/seg_train/seg_train/mountain/. /kaggle/working/train","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cp -a /kaggle/input/intel-image-classification/seg_train/seg_train/sea/. /kaggle/working/train","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cp -a /kaggle/input/intel-image-classification/seg_train/seg_train/street/. /kaggle/working/train","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames = os.listdir(\"/kaggle/working/train\")\nprint(len(filenames))","execution_count":11,"outputs":[{"output_type":"stream","text":"14034\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Preparing Training Data\n\n##Forest\nfilenames = os.listdir(\"/kaggle/input/intel-image-classification/seg_train/seg_train/forest/\")\nprint(len(filenames))\n\ndf_forest= pd.DataFrame({\n    'filename': filenames,\n    'category': 'forest'\n})\n\n##Glacier\nfilenames = os.listdir(\"/kaggle/input/intel-image-classification/seg_train/seg_train/glacier/\")\nprint(len(filenames))\n\ndf_glacier= pd.DataFrame({\n    'filename': filenames,\n    'category': 'glacier'\n})\n\n##Buildings\nfilenames = os.listdir(\"/kaggle/input/intel-image-classification/seg_train/seg_train/buildings/\")\nprint(len(filenames))\n\ndf_buildings= pd.DataFrame({\n    'filename': filenames,\n    'category': 'buildings'\n})\n\n##Sea\nfilenames = os.listdir(\"/kaggle/input/intel-image-classification/seg_train/seg_train/sea/\")\nprint(len(filenames))\n\ndf_sea= pd.DataFrame({\n    'filename': filenames,\n    'category': 'sea'\n})","execution_count":12,"outputs":[{"output_type":"stream","text":"2271\n2404\n2191\n2274\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"##street\n\nfilenames = os.listdir(\"/kaggle/input/intel-image-classification/seg_train/seg_train/street/\")\nprint(len(filenames))\n\ndf_street= pd.DataFrame({\n    'filename': filenames,\n    'category': 'street'\n})","execution_count":13,"outputs":[{"output_type":"stream","text":"2382\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Mountain\n\nfilenames = os.listdir(\"/kaggle/input/intel-image-classification/seg_train/seg_train/mountain/\")\nprint(len(filenames))\n\ndf_mountain= pd.DataFrame({\n    'filename': filenames,\n    'category': 'mountain'\n})","execution_count":14,"outputs":[{"output_type":"stream","text":"2512\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames = os.listdir(\"/kaggle/working/train\")\nprint(len(filenames))","execution_count":15,"outputs":[{"output_type":"stream","text":"14034\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cp -a /kaggle/input/intel-image-classification/seg_test/seg_test/forest/. /kaggle/working/test","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cp -a /kaggle/input/intel-image-classification/seg_test/seg_test/glacier/. /kaggle/working/test","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cp -a /kaggle/input/intel-image-classification/seg_test/seg_test/buildings/. /kaggle/working/test","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cp -a /kaggle/input/intel-image-classification/seg_test/seg_test/mountain/. /kaggle/working/test","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cp -a /kaggle/input/intel-image-classification/seg_test/seg_test/sea/. /kaggle/working/test","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cp -a /kaggle/input/intel-image-classification/seg_test/seg_test/street/. /kaggle/working/test","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames = os.listdir(\"/kaggle/working/test\")\nprint(len(filenames))","execution_count":22,"outputs":[{"output_type":"stream","text":"3000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Preparing Val Data\n\n##Forest\nfilenames = os.listdir(\"/kaggle/input/intel-image-classification/seg_test/seg_test/forest/\")\nprint(len(filenames))\n\ndf_forest_val= pd.DataFrame({\n    'filename': filenames,\n    'category': 'forest'\n})\n\n##Glacier\nfilenames = os.listdir(\"/kaggle/input/intel-image-classification/seg_test/seg_test/glacier/\")\nprint(len(filenames))\n\ndf_glacier_val= pd.DataFrame({\n    'filename': filenames,\n    'category': 'glacier'\n})\n\n##Buildings\nfilenames = os.listdir(\"/kaggle/input/intel-image-classification/seg_test/seg_test/buildings/\")\nprint(len(filenames))\n\ndf_buildings_val= pd.DataFrame({\n    'filename': filenames,\n    'category': 'buildings'\n})\n\n##Sea\nfilenames = os.listdir(\"/kaggle/input/intel-image-classification/seg_test/seg_test/sea/\")\nprint(len(filenames))\n\ndf_sea_val= pd.DataFrame({\n    'filename': filenames,\n    'category': 'sea'\n})\n\n##Mountain\nfilenames = os.listdir(\"/kaggle/input/intel-image-classification/seg_test/seg_test/mountain/\")\nprint(len(filenames))\n\ndf_mountain_val= pd.DataFrame({\n    'filename': filenames,\n    'category': 'mountain'\n})\n\n##street\nfilenames = os.listdir(\"/kaggle/input/intel-image-classification/seg_test/seg_test/street/\")\nprint(len(filenames))\n\ndf_street_val= pd.DataFrame({\n    'filename': filenames,\n    'category': 'street'\n})","execution_count":23,"outputs":[{"output_type":"stream","text":"474\n553\n437\n510\n525\n501\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Image Hyperparameters\n\nIMAGE_SIZE = 150\nIMAGE_WIDTH,IMAGE_HEIGHT = IMAGE_SIZE,IMAGE_SIZE\nIMAGE_SIZE = (IMAGE_HEIGHT,IMAGE_WIDTH)\nIMAGE_CHANNELS = 3","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Creating the Model\n\nfrom keras.applications import VGG16\n\ninput_shape = (IMAGE_HEIGHT,IMAGE_WIDTH,IMAGE_CHANNELS)\n\nmodel = Sequential()\n\npre_trained_model = VGG16(input_shape = input_shape , include_top = False , weights = 'imagenet')\n\nfor layer in pre_trained_model.layers[:15]:\n    layer.trainable = False\nfor layer in pre_trained_model.layers[15:]:\n    layer.trainable = True\n    \nlast_layer = pre_trained_model.get_layer('block5_pool')\nlast_output = last_layer.output\n\n# Flatten the output layer to 1 dimension\nx = Flatten()(last_output)\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = Dense(512, activation='relu')(x)\n# Add a dropout rate of 0.5\nx = Dropout(0.5)(x)\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = Dense(512, activation='relu')(x)\n# Add a dropout rate of 0.5\nx = Dropout(0.5)(x)\n# Add a final sigmoid layer for classification\nx = Dense(6, activation='softmax')(x)\n\n\nmodel = Model(pre_trained_model.input, x)","execution_count":25,"outputs":[{"output_type":"stream","text":"Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58892288/58889256 [==============================] - 2s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":26,"outputs":[{"output_type":"stream","text":"Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 150, 150, 3)       0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 8192)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               4194816   \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 512)               262656    \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 6)                 3078      \n=================================================================\nTotal params: 19,175,238\nTrainable params: 11,539,974\nNon-trainable params: 7,635,264\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Concatenating the DataFrames(Train)\n\nframes = [df_forest,df_glacier,df_buildings,df_mountain,df_sea,df_street]\ntrain_df = pd.concat(frames)","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Concatenating the DataFrames(Val)\n\nframes = [df_forest_val,df_glacier_val,df_buildings_val,df_mountain_val,df_sea_val,df_street_val]\nvalidate_df = pd.concat(frames)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df.shape)\nprint(validate_df.shape)","execution_count":29,"outputs":[{"output_type":"stream","text":"(14034, 2)\n(3000, 2)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Hyperparameters\n\ntotal_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]\nbatch_size= 64\nepochs = 20","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Generator\n\n##Train\ntrain_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1./255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    \"/kaggle/working/train\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","execution_count":31,"outputs":[{"output_type":"stream","text":"Found 14034 validated image filenames belonging to 6 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Val \nvalidation_datagen = ImageDataGenerator(rescale=1./255)\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    \"/kaggle/working/test\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","execution_count":32,"outputs":[{"output_type":"stream","text":"Found 3000 validated image filenames belonging to 6 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Callbacks\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_categorical_accuracy', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\nearlystop = EarlyStopping(patience=10)\n\ncallbacks = [earlystop, learning_rate_reduction]","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Compiling the Model\n\nfrom keras import optimizers\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.Adam(lr=1e-4),\n              metrics=['categorical_accuracy'])","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Training the Model\n\nhistory = model.fit_generator(\n    train_generator, \n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=total_validate//batch_size,\n    steps_per_epoch=total_train//batch_size,\n    callbacks=callbacks\n)","execution_count":35,"outputs":[{"output_type":"stream","text":"Epoch 1/20\n219/219 [==============================] - 89s 407ms/step - loss: 0.6624 - categorical_accuracy: 0.7564 - val_loss: 0.3609 - val_categorical_accuracy: 0.8903\nEpoch 2/20\n219/219 [==============================] - 87s 396ms/step - loss: 0.3821 - categorical_accuracy: 0.8724 - val_loss: 0.4597 - val_categorical_accuracy: 0.8917\nEpoch 3/20\n219/219 [==============================] - 87s 397ms/step - loss: 0.3305 - categorical_accuracy: 0.8888 - val_loss: 0.2573 - val_categorical_accuracy: 0.9118\nEpoch 4/20\n219/219 [==============================] - 86s 391ms/step - loss: 0.2861 - categorical_accuracy: 0.9037 - val_loss: 0.2579 - val_categorical_accuracy: 0.8924\nEpoch 5/20\n219/219 [==============================] - 87s 395ms/step - loss: 0.2596 - categorical_accuracy: 0.9122 - val_loss: 0.3076 - val_categorical_accuracy: 0.9172\nEpoch 6/20\n219/219 [==============================] - 87s 399ms/step - loss: 0.2294 - categorical_accuracy: 0.9199 - val_loss: 0.3663 - val_categorical_accuracy: 0.9223\nEpoch 7/20\n219/219 [==============================] - 86s 393ms/step - loss: 0.2112 - categorical_accuracy: 0.9277 - val_loss: 0.2246 - val_categorical_accuracy: 0.9183\nEpoch 8/20\n219/219 [==============================] - 87s 397ms/step - loss: 0.1998 - categorical_accuracy: 0.9292 - val_loss: 0.1709 - val_categorical_accuracy: 0.9142\n\nEpoch 00008: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 9/20\n219/219 [==============================] - 86s 392ms/step - loss: 0.1573 - categorical_accuracy: 0.9462 - val_loss: 0.1888 - val_categorical_accuracy: 0.9244\nEpoch 10/20\n219/219 [==============================] - 87s 399ms/step - loss: 0.1376 - categorical_accuracy: 0.9505 - val_loss: 0.2406 - val_categorical_accuracy: 0.9230\nEpoch 11/20\n219/219 [==============================] - 86s 393ms/step - loss: 0.1261 - categorical_accuracy: 0.9530 - val_loss: 0.2275 - val_categorical_accuracy: 0.9223\n\nEpoch 00011: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 12/20\n219/219 [==============================] - 87s 395ms/step - loss: 0.1070 - categorical_accuracy: 0.9619 - val_loss: 0.3329 - val_categorical_accuracy: 0.9203\nEpoch 13/20\n219/219 [==============================] - 87s 398ms/step - loss: 0.0943 - categorical_accuracy: 0.9686 - val_loss: 0.1194 - val_categorical_accuracy: 0.9213\n\nEpoch 00013: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 14/20\n219/219 [==============================] - 86s 393ms/step - loss: 0.0841 - categorical_accuracy: 0.9717 - val_loss: 0.1941 - val_categorical_accuracy: 0.9244\nEpoch 15/20\n219/219 [==============================] - 88s 403ms/step - loss: 0.0792 - categorical_accuracy: 0.9732 - val_loss: 0.4030 - val_categorical_accuracy: 0.9206\n\nEpoch 00015: ReduceLROnPlateau reducing learning rate to 1e-05.\nEpoch 16/20\n219/219 [==============================] - 87s 395ms/step - loss: 0.0729 - categorical_accuracy: 0.9754 - val_loss: 0.3851 - val_categorical_accuracy: 0.9189\nEpoch 17/20\n219/219 [==============================] - 89s 405ms/step - loss: 0.0663 - categorical_accuracy: 0.9771 - val_loss: 0.2879 - val_categorical_accuracy: 0.9275\nEpoch 18/20\n219/219 [==============================] - 87s 396ms/step - loss: 0.0641 - categorical_accuracy: 0.9775 - val_loss: 0.3860 - val_categorical_accuracy: 0.9138\nEpoch 19/20\n219/219 [==============================] - 88s 403ms/step - loss: 0.0582 - categorical_accuracy: 0.9797 - val_loss: 0.5448 - val_categorical_accuracy: 0.9149\nEpoch 20/20\n219/219 [==============================] - 87s 397ms/step - loss: 0.0610 - categorical_accuracy: 0.9787 - val_loss: 0.3155 - val_categorical_accuracy: 0.9240\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Acc of about 92%","execution_count":37,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}