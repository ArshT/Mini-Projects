{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"###Importing Important Libraries\n\nimport numpy as np\nimport pandas as pd\nimport keras\nimport matplotlib.pyplot as plt\nimport os\nimport random\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential,Model\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization,GlobalMaxPooling2D\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"###Unzipping the Data\nimport zipfile\n\n##Train\nlocal_zip_train = '/kaggle/input/dogs-vs-cats/train.zip'\nzip_ref = zipfile.ZipFile(local_zip_train, 'r')\nzip_ref.extractall('/kaggle/working')\nzip_ref.close()\n\n##Test\nlocal_zip_test = '/kaggle/input/dogs-vs-cats/test1.zip'\nzip_ref = zipfile.ZipFile(local_zip_test, 'r')\nzip_ref.extractall('/kaggle/working')\nzip_ref.close()","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Image Hyperparameters\n\nIMAGE_SIZE = 224\nIMAGE_WIDTH, IMAGE_HEIGHT = IMAGE_SIZE,IMAGE_SIZE\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS=3","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n###Preparing Training Data\n\nfilenames = os.listdir(\"/kaggle/working/train\")\nprint(len(filenames))\n\ncategories = []\nfor filename in filenames:\n    category = filename.split('.')[0]\n    if category == 'dog':\n        categories.append('dog')\n    else:\n        categories.append('cat')\n\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})","execution_count":4,"outputs":[{"output_type":"stream","text":"25000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"       filename category\n0  dog.1787.jpg      dog\n1  dog.9656.jpg      dog\n2  dog.2435.jpg      dog\n3  cat.4758.jpg      cat\n4  dog.5430.jpg      dog","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dog.1787.jpg</td>\n      <td>dog</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dog.9656.jpg</td>\n      <td>dog</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dog.2435.jpg</td>\n      <td>dog</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cat.4758.jpg</td>\n      <td>cat</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dog.5430.jpg</td>\n      <td>dog</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"            filename category\n24995   dog.4927.jpg      dog\n24996  cat.12390.jpg      cat\n24997   cat.1278.jpg      cat\n24998  dog.11691.jpg      dog\n24999   cat.5452.jpg      cat","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24995</th>\n      <td>dog.4927.jpg</td>\n      <td>dog</td>\n    </tr>\n    <tr>\n      <th>24996</th>\n      <td>cat.12390.jpg</td>\n      <td>cat</td>\n    </tr>\n    <tr>\n      <th>24997</th>\n      <td>cat.1278.jpg</td>\n      <td>cat</td>\n    </tr>\n    <tr>\n      <th>24998</th>\n      <td>dog.11691.jpg</td>\n      <td>dog</td>\n    </tr>\n    <tr>\n      <th>24999</th>\n      <td>cat.5452.jpg</td>\n      <td>cat</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Creating the Model\nfrom keras.applications import VGG16\n\ninput_shape = (IMAGE_HEIGHT,IMAGE_WIDTH,IMAGE_CHANNELS)\n\npre_trained_model = VGG16(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n\nfor layer in pre_trained_model.layers[:15]:\n    layer.trainable = False\nfor layer in pre_trained_model.layers[15:]:\n    layer.trainable = True\n    \nlast_layer = pre_trained_model.get_layer('block5_pool')\nlast_output = last_layer.output\n\n# Flatten the output layer to 1 dimension\nx = GlobalMaxPooling2D()(last_output)\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = Dense(512, activation='relu')(x)\n# Add a dropout rate of 0.5\nx = Dropout(0.5)(x)\n# Add a final sigmoid layer for classification\nx = Dense(1, activation='sigmoid')(x)\n\nmodel = Model(pre_trained_model.input, x)","execution_count":7,"outputs":[{"output_type":"stream","text":"Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58892288/58889256 [==============================] - 3s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import optimizers\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.Adam(lr=1e-4),\n              metrics=['accuracy'])","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n###Callbacks\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\nearlystop = EarlyStopping(patience=10)\n\ncallbacks = [earlystop, learning_rate_reduction]","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n###Preparing the Data\n\ntrain_df, validate_df = train_test_split(df, test_size=0.10, random_state=42)\ntrain_df = train_df.reset_index(drop=True)\nvalidate_df = validate_df.reset_index(drop=True)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Hyperparameters\n\n\ntotal_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]\nbatch_size= 16\nepochs = 5","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Generator\n\n##Train\ntrain_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1./255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    \"/kaggle/working/train\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='binary',\n    batch_size=batch_size\n)\n","execution_count":12,"outputs":[{"output_type":"stream","text":"Found 22500 validated image filenames belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Val \nvalidation_datagen = ImageDataGenerator(rescale=1./255)\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    \"/kaggle/working/train\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='binary',\n    batch_size=batch_size\n)","execution_count":13,"outputs":[{"output_type":"stream","text":"Found 2500 validated image filenames belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Training the Model\n\nhistory = model.fit_generator(\n    train_generator, \n    epochs=5,\n    validation_data=validation_generator,\n    validation_steps=total_validate//batch_size,\n    steps_per_epoch=total_train//batch_size,\n    callbacks=callbacks\n)","execution_count":14,"outputs":[{"output_type":"stream","text":"Epoch 1/5\n1406/1406 [==============================] - 316s 224ms/step - loss: 0.1687 - accuracy: 0.9278 - val_loss: 0.1773 - val_accuracy: 0.9647\nEpoch 2/5\n   1/1406 [..............................] - ETA: 1:09 - loss: 0.1201 - accuracy: 0.9375","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy,lr\n  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n","name":"stderr"},{"output_type":"stream","text":"1406/1406 [==============================] - 311s 221ms/step - loss: 0.1022 - accuracy: 0.9578 - val_loss: 0.0154 - val_accuracy: 0.9722\nEpoch 3/5\n1406/1406 [==============================] - 305s 217ms/step - loss: 0.0805 - accuracy: 0.9680 - val_loss: 0.0164 - val_accuracy: 0.9710racy: \nEpoch 4/5\n1406/1406 [==============================] - 300s 213ms/step - loss: 0.0676 - accuracy: 0.9721 - val_loss: 0.0164 - val_accuracy: 0.9775\nEpoch 5/5\n1406/1406 [==============================] - 299s 213ms/step - loss: 0.0594 - accuracy: 0.9759 - val_loss: 0.0196 - val_accuracy: 0.9758\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}